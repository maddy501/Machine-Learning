{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_&_Fine_Tuning_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJa2y_mreMYm"
      },
      "source": [
        "# **Hyperparameter tuning with GridSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkVVsEa1femC"
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Setup the hyperparameter grid\n",
        "c_space = np.logspace(-5, 8, 15)\n",
        "param_grid = {'C': c_space}\n",
        "\n",
        "# Instantiate a logistic regression classifier: logreg\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
        "\n",
        "# Fit it to the data\n",
        "logreg_cv.fit(X,y)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
        "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo_xizDCgSRj"
      },
      "source": [
        "# **Hyperparameter tuning with RandomizedSearchCV and Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L42bkO9gWwF"
      },
      "source": [
        "# Import necessary modules\n",
        "from scipy.stats import randint\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Setup the parameters and distributions to sample from: param_dist\n",
        "param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Instantiate a Decision Tree classifier: tree\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object: tree_cv\n",
        "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
        "\n",
        "# Fit it to the data\n",
        "tree_cv.fit(X,y)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
        "print(\"Best score is {}\".format(tree_cv.best_score_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZdXJmD8jBHc"
      },
      "source": [
        "# **Hold-out set in practice I: Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfv9Q0q5jDiS"
      },
      "source": [
        "Create the hyperparameter grid:\n",
        "Use the array c_space as the grid of values for 'C'.\n",
        "For 'penalty', specify a list consisting of 'l1' and 'l2'.\n",
        "Instantiate a logistic regression classifier.\n",
        "Create training and test sets. Use a test_size of 0.4 and random_state of 42. In practice, the test set here will function as the hold-out set.\n",
        "Tune the hyperparameters on the training set using GridSearchCV with 5-folds. This involves first instantiating the GridSearchCV object with the correct parameters and then fitting it to the training data.\n",
        "Print the best parameter and best score obtained from GridSearchCV by accessing the best_params_ and best_score_ attributes of logreg_cv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE7n8hWrjGwC"
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the hyperparameter grid\n",
        "c_space = np.logspace(-5, 8, 15)\n",
        "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Instantiate the logistic regression classifier: logreg\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4, random_state=42)\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "logreg_cv = GridSearchCV(logreg,param_grid,cv=5)\n",
        "\n",
        "# Fit it to the training data\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "# Print the optimal parameters and best score\n",
        "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMEf9i2JlH9x"
      },
      "source": [
        "# **Hold-out set in practice II: Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R858AwYolMzO"
      },
      "source": [
        "There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the L1\n",
        " and L2\n",
        " penalties:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joPgUC6glNnh"
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV,train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
        "\n",
        "# Create the hyperparameter grid\n",
        "l1_space = np.linspace(0, 1, 30)\n",
        "param_grid = {'l1_ratio': l1_space}\n",
        "\n",
        "# Instantiate the ElasticNet regressor: elastic_net\n",
        "elastic_net = ElasticNet()\n",
        "\n",
        "# Setup the GridSearchCV object: gm_cv\n",
        "gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
        "\n",
        "# Fit it to the training data\n",
        "gm_cv.fit(X_train,y_train)\n",
        "# Predict on the test set and compute metrics\n",
        "y_pred = gm_cv.predict(X_test)\n",
        "r2 = gm_cv.score(X_test, y_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
        "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
        "print(\"Tuned ElasticNet MSE: {}\".format(mse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccZfBhxA006v"
      },
      "source": [
        "**Assignment Question **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4qz2GVM0zZm"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "# Seperating features from predictor and dropping the recording_date_time column\n",
        "X = weather_data_with_dummy.drop(['recording_date_time','temperature'],axis = 1).values\n",
        "y = weather_data_with_dummy['temperature'].values\n",
        "\n",
        "# Instantiate the ElasticNet regressor: elastic_net\n",
        "elastic_net = ElasticNet(normalize = True)\n",
        "\n",
        "# Dividing the data into 40/60 ratio and doing a number of splits of 10\n",
        "ss = ShuffleSplit(n_splits = 10, test_size = 0.60,train_size = 0.40, random_state = 0)\n",
        "\n",
        "# Create the hyperparameter grid\n",
        "param_grid = {'alpha':[1e-5,1e-4,1e-3,1e-2,1e-1,1,2,3,4,5], 'l1_ratio':[1e-5,1e-4,1e-3,1e-2,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
        "\n",
        "# Setup the GridSearchCV object: using elastic net\n",
        "gm_cv = GridSearchCV(elastic_net, param_grid, scoring='neg_mean_absolute_error' , cv=ss)\n",
        "\n",
        "# Fit it to the  data\n",
        "gm_cv.fit(X,y)\n",
        "\n",
        "# Found the best parameters\n",
        "print(\"Best Parameters: \",gm_cv.best_params_)\n",
        "print(\"Mean Absolute Error is:\",-gm_cv.best_score_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}